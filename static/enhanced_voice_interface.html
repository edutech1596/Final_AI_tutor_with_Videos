<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>🎓 AI Math Tutor - Multimodal Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            width: 100%;
            margin: 0 auto;
        }

        .header {
            background: white;
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            text-align: center;
        }

        .header h1 {
            color: #667eea;
            font-size: 2.2em;
            margin-bottom: 10px;
        }

        .header p {
            color: #6b7280;
            font-size: 1.1em;
        }

        .main-card {
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            margin-bottom: 20px;
        }

        .settings-row {
            display: flex;
            gap: 20px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        .form-group {
            flex: 1;
            min-width: 200px;
        }

        .form-group label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #374151;
        }

        .form-group input, .form-group select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e5e7eb;
            border-radius: 10px;
            font-size: 16px;
            transition: border-color 0.3s;
        }

        .form-group input:focus, .form-group select:focus {
            outline: none;
            border-color: #667eea;
        }

        /* Audio Toggle Styles */
        .audio-toggle-container {
            display: flex;
            align-items: center;
            gap: 10px;
            background: #f8fafc;
            padding: 15px;
            border-radius: 12px;
            border: 2px solid #e5e7eb;
        }

        .audio-toggle {
            position: relative;
            width: 50px;
            height: 24px;
            background: #e5e7eb;
            border-radius: 12px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        .audio-toggle.active {
            background: #10b981;
        }

        .audio-toggle-indicator {
            position: absolute;
            top: 2px;
            left: 2px;
            width: 20px;
            height: 20px;
            background: white;
            border-radius: 50%;
            transition: transform 0.3s;
        }

        .audio-toggle.active .audio-toggle-indicator {
            transform: translateX(26px);
        }

        .audio-toggle-text {
            font-weight: 600;
            color: #374151;
        }

        /* Enhanced Multimodal Chatbar */
        .chatbar-container {
            background: #f8fafc;
            border: 2px solid #e5e7eb;
            border-radius: 16px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .chat-input-area {
            position: relative;
        }

        .input-row {
            display: flex;
            align-items: flex-end;
            gap: 12px;
        }

        .chat-text-input {
            flex: 1;
            min-height: 50px;
            max-height: 120px;
            padding: 15px 20px;
            border: 2px solid #e5e7eb;
            border-radius: 12px;
            font-size: 16px;
            font-family: inherit;
            resize: none;
            transition: all 0.3s;
            background: white;
        }

        .chat-text-input:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }

        .input-actions {
            display: flex;
            gap: 8px;
            align-items: center;
        }

        .input-btn {
            width: 44px;
            height: 44px;
            border: none;
            border-radius: 12px;
            background: #f3f4f6;
            color: #6b7280;
            font-size: 18px;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .input-btn:hover {
            background: #e5e7eb;
            color: #374151;
        }

        .input-btn.active {
            background: #667eea;
            color: white;
        }

        .send-btn {
            background: #667eea;
            color: white;
            width: 44px;
            height: 44px;
            border: none;
            border-radius: 12px;
            font-size: 18px;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .send-btn:hover {
            background: #5a67d8;
            transform: translateY(-1px);
        }

        .send-btn:disabled {
            background: #d1d5db;
            cursor: not-allowed;
            transform: none;
        }

        /* Image Preview */
        /* Clean image attachment indicator */
        .image-attachment {
            display: none;
            align-items: center;
            gap: 8px;
            margin-top: 12px;
            padding: 8px 12px;
            background: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            font-size: 14px;
            color: #64748b;
        }

        .image-attachment.has-image {
            display: flex;
        }

        .image-icon {
            width: 16px;
            height: 16px;
            background: #3b82f6;
            border-radius: 3px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 10px;
        }

        .image-filename {
            flex: 1;
            font-weight: 500;
        }

        .image-remove {
            background: none;
            border: none;
            color: #ef4444;
            cursor: pointer;
            padding: 2px;
            border-radius: 4px;
        }

        .image-remove:hover {
            background: #fee2e2;
        }

        .remove-image-btn {
            background: #ef4444;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 14px;
            transition: background 0.3s;
        }

        .remove-image-btn:hover {
            background: #dc2626;
        }

        /* Status and Response Display */
        .status {
            text-align: center;
            padding: 20px;
            font-size: 1.1em;
            color: #6b7280;
            font-weight: 500;
        }

        .response-container {
            background: #f8fafc;
            border-radius: 16px;
            padding: 20px;
            margin-top: 20px;
            border: 2px solid #e5e7eb;
            /* ChatGPT-style layout: flexible height with proper scrolling */
            height: 60vh; /* Fixed height for consistent layout */
            overflow-y: auto;
            scroll-behavior: smooth;
            word-wrap: break-word;
            white-space: pre-wrap;
            /* Ensure proper scrolling */
            max-width: 100%;
            /* Future video player compatibility */
            position: relative;
            /* Ensure content is visible */
            display: block;
        }

        .response-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #e5e7eb;
        }

        .response-title {
            font-weight: 600;
            color: #374151;
            font-size: 1.1em;
        }

        .response-meta {
            font-size: 0.9em;
            color: #6b7280;
        }

        .response-content {
            line-height: 1.6;
            color: #374151;
            background: #f8fafc;
            border-left: 4px solid #10b981;
            padding: 15px;
            margin-bottom: 15px;
            border-radius: 8px;
            /* Ensure no truncation like ChatGPT - remove all height constraints */
            height: auto;
            overflow: visible;
            word-wrap: break-word;
            white-space: pre-wrap;
            /* Remove any max-height that might cause truncation */
            max-height: none;
        }

        .response-content strong {
            color: #065f46;
            display: block;
            margin-bottom: 8px;
        }

        .user-message {
            background: #e0f2fe;
            border-left: 4px solid #0ea5e9;
            padding: 15px;
            margin-bottom: 15px;
            border-radius: 8px;
            /* Ensure no truncation like ChatGPT - remove all height constraints */
            height: auto;
            overflow: visible;
            word-wrap: break-word;
            white-space: pre-wrap;
            /* Remove any max-height that might cause truncation */
            max-height: none;
        }

        .user-message strong {
            color: #0c4a6e;
            display: block;
            margin-bottom: 8px;
        }

        .user-message p {
            margin: 5px 0;
        }

        .message-image {
            margin-top: 10px;
        }

        .message-image img {
            max-width: 200px;
            border-radius: 8px;
            border: 2px solid #0ea5e9;
        }

        /* Audio Controls */
        .audio-controls {
            display: flex;
            align-items: center;
            gap: 8px;
            margin: 10px 0;
            padding: 8px 12px;
            background: #f8fafc;
            border-radius: 8px;
            border: 1px solid #e2e8f0;
        }

        .play-btn, .stop-btn {
            padding: 6px 10px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 12px;
            transition: all 0.2s;
            min-width: 32px;
            height: 32px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .play-btn {
            background: #10b981;
            color: white;
        }

        .play-btn:hover {
            background: #059669;
            transform: scale(1.05);
        }

        .stop-btn {
            background: #ef4444;
            color: white;
        }

        .stop-btn:hover {
            background: #dc2626;
            transform: scale(1.05);
        }

        .stop-btn:disabled {
            background: #d1d5db;
            cursor: not-allowed;
            transform: none;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }

            .header {
                padding: 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .main-card {
                padding: 20px;
            }

            .settings-row {
                flex-direction: column;
                gap: 15px;
            }

            .input-row {
                flex-direction: column;
                align-items: stretch;
            }

            .input-actions {
                justify-content: center;
            }
        }

        /* Hidden file input */
        #imageFileInput {
            display: none;
        }

        /* Q&A Pair Styling */
        .qa-pair {
            margin-bottom: 30px;
            border-left: 3px solid #3b82f6;
            padding-left: 15px;
            background: #f8fafc;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .qa-pair .user-message {
            margin-bottom: 15px;
            padding: 10px;
            background: #e0f2fe;
            border-radius: 6px;
            border-left: 3px solid #0ea5e9;
        }

        .qa-pair .response-content {
            padding: 10px;
            background: #f0fdf4;
            border-radius: 6px;
            border-left: 3px solid #22c55e;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <div class="header">
            <h1>🎓 AI Math Tutor</h1>
            <p>Multimodal Chat Interface - Type, Speak, or Upload Images</p>
        </div>

        <!-- Future Video Player Integration Area -->
        <!-- <div class="video-player-container" style="display: none;">
            <video id="mathVideo" controls style="width: 100%; height: 300px; border-radius: 8px;">
                <source src="" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </div> -->

        <!-- Main Interface -->
        <div class="main-card">
            <!-- Settings Row -->
            <div class="settings-row">
                <div class="form-group">
                    <label for="userId">User ID</label>
                    <input type="text" id="userId" value="user123" placeholder="Enter your user ID">
                </div>
                <div class="form-group">
                    <label for="videoId">Video ID</label>
                    <select id="videoId">
                        <option value="Area_Circle">Area of a Circle</option>
                        <option value="PythagoreanTheorem">Pythagorean Theorem</option>
                        <option value="QuadraticFormula">Quadratic Formula</option>
                    </select>
                </div>
                <div class="form-group">
                    <label for="languageSelect">Language</label>
                    <select id="languageSelect">
                        <option value="">Auto-detect</option>
                        <option value="en">English</option>
                        <option value="es">Spanish</option>
                        <option value="fr">French</option>
                        <option value="de">German</option>
                        <option value="it">Italian</option>
                        <option value="pt">Portuguese</option>
                        <option value="ru">Russian</option>
                        <option value="zh">Chinese (Simplified)</option>
                        <option value="ja">Japanese</option>
                        <option value="ko">Korean</option>
                        <option value="ar">Arabic</option>
                        <option value="hi">Hindi</option>
                        <option value="ta">Tamil</option>
                        <option value="te">Telugu</option>
                        <option value="bn">Bengali</option>
                        <option value="mr">Marathi</option>
                        <option value="gu">Gujarati</option>
                        <option value="kn">Kannada</option>
                        <option value="ml">Malayalam</option>
                        <option value="pa">Punjabi</option>
                        <option value="ur">Urdu</option>
                        <option value="nl">Dutch</option>
                        <option value="pl">Polish</option>
                        <option value="tr">Turkish</option>
                        <option value="vi">Vietnamese</option>
                        <option value="th">Thai</option>
                        <option value="id">Indonesian</option>
                        <option value="ms">Malay</option>
                        <option value="uk">Ukrainian</option>
                        <option value="cs">Czech</option>
                        <option value="ro">Romanian</option>
                        <option value="sv">Swedish</option>
                        <option value="no">Norwegian</option>
                        <option value="da">Danish</option>
                        <option value="fi">Finnish</option>
                    </select>
                </div>
            </div>

            <!-- Audio Output Toggle -->
            <div class="audio-toggle-container">
                <div class="audio-toggle" id="audioToggle">
                    <div class="audio-toggle-indicator"></div>
                </div>
                <span class="audio-toggle-text" id="audioToggleText">🔇 Audio Output: OFF</span>
            </div>

            <!-- Enhanced Multimodal Chatbar -->
            <div class="chatbar-container">
                <div class="chat-input-area">
                    <div class="input-row">
                        <textarea 
                            id="textInput" 
                            class="chat-text-input" 
                            placeholder="Type your question here... (or use voice/image)"
                            rows="1"
                        ></textarea>
                        <div class="input-actions">
                            <button id="imageUploadBtn" class="input-btn" title="Upload Image">📎</button>
                            <button id="voiceBtn" class="input-btn" title="Voice Input">🎤</button>
                            <button id="sendBtn" class="send-btn" title="Send Message">➤</button>
                        </div>
                    </div>
                    
                    <!-- Image Attachment Indicator -->
                    <div id="imageAttachment" class="image-attachment">
                        <div class="image-icon">📷</div>
                        <span id="imageFilename" class="image-filename">image.jpg</span>
                        <button id="imageRemove" class="image-remove" title="Remove image">×</button>
                    </div>
                </div>
                
                <!-- Hidden file input -->
                <input type="file" id="imageFileInput" accept="image/*">
            </div>

            <!-- Status -->
            <div id="status" class="status">Ready to help! Type, speak, or upload an image</div>

            <!-- Response Container -->
            <div id="responseContainer" class="response-container" style="display: none;">
                <div class="response-header">
                    <div class="response-title">AI Tutor Response</div>
                    <div class="response-meta" id="responseMeta"></div>
                </div>
                <div class="audio-controls" id="audioControls" style="display: none;">
                    <button id="playBtn" class="play-btn">▶️</button>
                    <button id="stopBtn" class="stop-btn" disabled>⏹️</button>
                </div>
                <div id="responseContent" class="response-content"></div>
            </div>
        </div>
    </div>

    <script>
        // Global state
        let currentImageFile = null;
        let currentImageBase64 = null;
        let isRecording = false;
        let currentAudio = null;
        let audioOutputEnabled = false; // default OFF to save latency & cost

        // Initialize the enhanced multimodal chatbar
        function initializeMultimodalChatbar() {
            console.log('🚀 Initializing Enhanced Multimodal Chatbar');
            
            // Get elements
            const textInput = document.getElementById('textInput');
            const imageUploadBtn = document.getElementById('imageUploadBtn');
            const voiceBtn = document.getElementById('voiceBtn');
            const sendBtn = document.getElementById('sendBtn');
            const imageFileInput = document.getElementById('imageFileInput');
            const imageAttachment = document.getElementById('imageAttachment');
            const imageFilename = document.getElementById('imageFilename');
            const imageRemove = document.getElementById('imageRemove');
            const audioToggle = document.getElementById('audioToggle');
            const audioToggleText = document.getElementById('audioToggleText');
            const playBtn = document.getElementById('playBtn');
            const stopBtn = document.getElementById('stopBtn');

            // Text input auto-resize
            textInput.addEventListener('input', function() {
                this.style.height = 'auto';
                this.style.height = Math.min(this.scrollHeight, 120) + 'px';
                updateSendButtonState();
            });

            // Enter key to send
            textInput.addEventListener('keydown', function(e) {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    handleSendMessage();
                }
            });

            // Paste handler: support pasting images (screenshots/clipboard)
            textInput.addEventListener('paste', async function(e) {
                try {
                    const items = (e.clipboardData || window.clipboardData)?.items || [];
                    for (let i = 0; i < items.length; i++) {
                        const item = items[i];
                        if (item && item.type && item.type.startsWith('image/')) {
                            const file = item.getAsFile();
                            if (file) {
                                e.preventDefault();
                                await handleImageUpload(file);
                                return; // only take the first image
                            }
                        }
                    }
                } catch (err) {
                    console.warn('Paste image handler error:', err);
                }
            });

            // Image upload button
            imageUploadBtn.addEventListener('click', () => {
                imageFileInput.click();
            });

            // File input change
            imageFileInput.addEventListener('change', function(e) {
                const file = e.target.files[0];
                if (file) {
                    handleImageUpload(file);
                }
            });

            // Voice button
            voiceBtn.addEventListener('click', function() {
                if (isRecording) {
                    stopRecording();
                } else {
                    startRecording();
                }
            });

            // Send button
            sendBtn.addEventListener('click', handleSendMessage);

            // Remove image button
            imageRemove.addEventListener('click', removeImage);

            // Audio toggle
            audioToggle.addEventListener('click', toggleAudioOutput);

            // Audio controls
            playBtn.addEventListener('click', playCurrentAudio);
            stopBtn.addEventListener('click', stopCurrentAudio);

            // Drag and drop for images
            textInput.addEventListener('dragover', function(e) {
                e.preventDefault();
                this.style.borderColor = '#667eea';
            });

            textInput.addEventListener('dragleave', function(e) {
                e.preventDefault();
                this.style.borderColor = '#e5e7eb';
            });

            textInput.addEventListener('drop', function(e) {
                e.preventDefault();
                this.style.borderColor = '#e5e7eb';
                
                const files = e.dataTransfer.files;
                if (files.length > 0 && files[0].type.startsWith('image/')) {
                    handleImageUpload(files[0]);
                }
            });

            console.log('✅ Enhanced Multimodal Chatbar initialized');
        }

        // Handle image upload
        async function handleImageUpload(file) {
            console.log('📷 Handling image upload:', file.name);
            
            // Validate file type
            if (!file.type.startsWith('image/')) {
                displayError('Invalid file type', 'Please select an image file');
                return;
            }
            
            // Validate file size (max 10MB)
            if (file.size > 10 * 1024 * 1024) {
                displayError('File too large', 'Please select an image smaller than 10MB');
                return;
            }
            
            try {
                // Convert to base64
                const base64 = await fileToBase64(file);
                currentImageFile = file;
                currentImageBase64 = base64;
                
                // Show clean attachment indicator
                imageFilename.textContent = file.name;
                imageAttachment.classList.add('has-image');
                
                // Update send button
                updateSendButtonState();
                
                console.log('✅ Image uploaded successfully');
                
            } catch (error) {
                console.error('❌ Image processing error:', error);
                displayError('Failed to process image', 'Please try again');
            }
        }

        // Remove image
        function removeImage() {
            currentImageFile = null;
            currentImageBase64 = null;
            
            imageAttachment.classList.remove('has-image');
            
            // Clear file input
            document.getElementById('imageFileInput').value = '';
            
            updateSendButtonState();
        }

        // Lightbox interactions (global)
        (function setupLightbox(){
            const lightbox = document.getElementById('lightbox');
            const img = document.getElementById('lightboxImg');
            if (!lightbox) return;
            lightbox.addEventListener('click', ()=>{ lightbox.style.display='none'; img.src=''; });
            document.addEventListener('keydown', (e)=>{ if(e.key==='Escape'){ lightbox.style.display='none'; img.src=''; }});
        })();

        // Update send button state
        function updateSendButtonState() {
            const textInput = document.getElementById('textInput');
            const sendBtn = document.getElementById('sendBtn');
            const hasText = textInput.value.trim().length > 0;
            const hasImage = currentImageFile !== null;
            const isRecording = document.getElementById('voiceBtn').classList.contains('active');
            
            sendBtn.disabled = !hasText && !hasImage && !isRecording;
        }

        // Handle send message
        async function handleSendMessage() {
            const textInput = document.getElementById('textInput');
            const text = textInput.value.trim();
            const hasImage = currentImageFile !== null;
            
            if (!text && !hasImage) {
                displayError('No input', 'Please type a question, upload an image, or use voice input');
                return;
            }
            
            try {
                if (hasImage) {
                    // Handle image + text input
                    await handleImageTextInput(text);
                } else {
                    // Handle text-only input
                    await handleTextInput(text);
                }
            } catch (error) {
                console.error('❌ Send message error:', error);
                displayError('Failed to send message', 'Please try again');
            }
        }

        // Handle text-only input
        async function handleTextInput(text) {
            console.log('📝 Handling text input:', text);
            
            // Clear text input
            document.getElementById('textInput').value = '';
            document.getElementById('textInput').style.height = 'auto';
            
            // Show user message
            displayUserMessage(text, 'text');
            
            // Send to main API
            await sendToMainAPI(text, null);
        }

        // Handle image + text input
        async function handleImageTextInput(text) {
            console.log('📷 Handling image + text input:', text);
            
            // Store image data before clearing
            const imageData = currentImageBase64;
            
            // Clear inputs
            document.getElementById('textInput').value = '';
            document.getElementById('textInput').style.height = 'auto';
            removeImage();
            
            // Store user message data and display question immediately for image input
            displayUserMessage(text, 'image', imageData);
            
            // Display the user's question immediately for image input
            const responseContainer = document.getElementById('responseContainer');
            const responseContent = document.getElementById('responseContent');
            responseContainer.style.display = 'block';
            
            let messageHtml = `<div class="qa-pair" style="margin-bottom: 30px; border-left: 3px solid #3b82f6; padding-left: 15px; background: #f8fafc; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">`;
            messageHtml += `<div class="user-message" style="margin-bottom: 15px; padding: 10px; background: #e0f2fe; border-radius: 6px; border-left: 3px solid #0ea5e9;">`;
            messageHtml += `<strong>You asked:</strong> ${text}`;
            
            if (imageData) {
                messageHtml += `<div class="message-image" style="margin-top: 10px;">`;
                messageHtml += `<img src="data:image/jpeg;base64,${imageData}" alt="Uploaded image" style="max-width: 200px; border-radius: 4px;">`;
                messageHtml += `</div>`;
            }
            
            messageHtml += `</div>`;
            messageHtml += `<div class="response-content" style="padding: 10px; background: #f0fdf4; border-radius: 6px; border-left: 3px solid #22c55e;">`;
            messageHtml += `<strong>AI Answer:</strong><br><div id="imageProcessingAns" style="white-space: pre-wrap; line-height: 1.6; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;"></div></div>`;
            messageHtml += `</div>`;
            
            // Prepend new user messages to top (notebook style) - user question at top
            responseContent.innerHTML = messageHtml + responseContent.innerHTML;
            
            // Auto-scroll to top to show the new question
            setTimeout(() => {
                responseContainer.scrollTop = 0;
            }, 100);
            
            // Process image first
            try {
                const response = await fetch('http://localhost:5001/api/process_image', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        image_base64: imageData,
                        processing_type: 'comprehensive',
                        user_id: document.getElementById('userId').value || 'user123',
                        video_id: document.getElementById('videoId').value || 'Area_Circle'
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    console.log('✅ Image processed successfully:', result.result);
                    
                    // Send combined text + image context to main API
                    await sendToMainAPI(text, result.result);
                } else {
                    console.error('❌ Image processing failed:', result.error);
                    displayError('Image processing failed', result.error);
                }
                
            } catch (error) {
                console.error('❌ Image processing error:', error);
                displayError('Failed to process image', 'Please try again');
            }
        }

        // Send to main API
        async function sendToMainAPI(text, imageAnalysis) {
            try {
                console.log('🔄 Sending to main API:', text);
                
                // Get current user and video IDs
                const userId = document.getElementById('userId').value || 'user123';
                const videoId = document.getElementById('videoId').value || 'Area_Circle';
                const language = document.getElementById('languageSelect').value || 'en';
                
                // Keep user's original question separate from vision API context
                const userQuestion = text; // This is what the user actually asked
                
                // Combine text with image context for LLM processing (but don't show to user)
                let combinedText = text;
                if (imageAnalysis) {
                    const vision = imageAnalysis.vision_analysis?.analysis || '';
                    const extracted = imageAnalysis.extracted_text || '';
                    const maths = Array.isArray(imageAnalysis.math_equations) ? imageAnalysis.math_equations.join('; ') : '';
                    const parts = [];
                    if (extracted) parts.push(`Extracted text: ${extracted}`);
                    if (maths) parts.push(`Detected math: ${maths}`);
                    if (vision) parts.push(`Vision analysis: ${vision}`);
                    combinedText = `${text}\n\nImage context:\n${parts.join('\n') || 'Image uploaded, analysis unavailable'}`;

                    // Heuristic: detect radius like "r = 17 cm" and hint area for circles
                    try {
                        const txt = (extracted || vision || '').toLowerCase();
                        const m = txt.match(/(radius|\br\b)\s*[:=]?\s*(\d+(?:\.\d+)?)\s*(cm|mm|m)?/);
                        if (m) {
                            const r = parseFloat(m[2]);
                            if (!isNaN(r)) {
                                const area = Math.PI * r * r;
                                combinedText += `\n\nDetected radius r=${r}. Estimated area ≈ ${area.toFixed(2)} square units.`;
                            }
                        }
                    } catch (e) { /* ignore */ }
                }
                
                // Use streaming when audio is OFF to reduce latency
                if (!audioOutputEnabled) {
                    return await sendToMainAPIStreaming(combinedText, userId, videoId, language, userQuestion);
                }

                const response = await fetch('http://localhost:5001/api/ask_tutor', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        user_id: userId,
                        video_id: videoId,
                        question_text: combinedText,
                        language: language,
                        audio_output: audioOutputEnabled
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    console.log('✅ Main API response received');
                    
                    // Display the response (user question already shown by sendMessage)
                    displayResponse(result.answer, result.session_info, result.language);
                    
                    // Play audio if available and enabled
                    if (result.audio_base64 && audioOutputEnabled) {
                        playAudio(result.audio_base64);
                    }
                } else {
                    console.error('❌ Main API failed:', result.error);
                    displayError('Failed to get response', result.error);
                }
                
            } catch (error) {
                console.error('❌ Main API error:', error);
                displayError('Failed to send to main API', 'Please try again');
            }
        }

        // Streaming mode (text-first when audio toggle is OFF)
        async function sendToMainAPIStreaming(combinedText, userId, videoId, language, userQuestion = null) {
            const responseContainer = document.getElementById('responseContainer');
            const responseContent = document.getElementById('responseContent');
            responseContainer.style.display = 'block';
            
            // Check if this is an image input that already has a Q&A pair displayed
            if (currentQuestionType === 'image') {
                // Find the first Q&A pair (most recent) and update its answer for streaming
                const firstQAPair = responseContent.querySelector('.qa-pair');
                if (firstQAPair) {
                    const answerDiv = firstQAPair.querySelector('#imageProcessingAns');
                    if (answerDiv) {
                        // Set up for streaming
                        answerDiv.innerHTML = '';
                        answerDiv.id = 'streamAns'; // Change ID for streaming updates
                    }
                }
            } else {
                // For text and voice inputs, create complete Q&A pair HTML for streaming
                let qaPairHtml = `<div class="qa-pair" style="margin-bottom: 30px; border-left: 3px solid #3b82f6; padding-left: 15px; background: #f8fafc; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">`;
                
                // Add the question part
                if (currentQuestion) {
                    qaPairHtml += `<div class="user-message" style="margin-bottom: 15px; padding: 10px; background: #e0f2fe; border-radius: 6px; border-left: 3px solid #0ea5e9;">`;
                    qaPairHtml += `<strong>You asked:</strong> ${currentQuestion}`;
                    
                    if (currentQuestionType === 'image' && currentQuestionImage) {
                        qaPairHtml += `<div class="message-image" style="margin-top: 10px;">`;
                        qaPairHtml += `<img src="data:image/jpeg;base64,${currentQuestionImage}" alt="Uploaded image" style="max-width: 200px; border-radius: 4px;">`;
                        qaPairHtml += `</div>`;
                    }
                    qaPairHtml += `</div>`;
                }
                
                // Add the streaming answer part
                qaPairHtml += `<div class="response-content" style="padding: 10px; background: #f0fdf4; border-radius: 6px; border-left: 3px solid #22c55e;">`;
                qaPairHtml += `<strong>AI Answer:</strong><br><div id="streamAns" style="white-space: pre-wrap; line-height: 1.6; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;"></div></div>`;
                qaPairHtml += `</div>`;
                
                // Prepend complete Q&A pair to top
                responseContent.innerHTML = qaPairHtml + responseContent.innerHTML;
            }

            const resp = await fetch('http://localhost:5001/api/ask_tutor_stream_optimized', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ user_id: userId, video_id: videoId, question_text: combinedText, language })
            });
            if (!resp.body) return;
            const reader = resp.body.getReader();
            const decoder = new TextDecoder();
            let finalAudio = null;
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const chunk = decoder.decode(value);
                chunk.split('\n').forEach(line => {
                    if (line.startsWith('data:')) {
                        try {
                            const data = JSON.parse(line.slice(5).trim());
                            if (data.type === 'token') {
                                const el = document.getElementById('streamAns');
                                // Clean LaTeX and markdown for display
                                const cleanedContent = cleanMarkdownForDisplay(data.content);
                                el.textContent += cleanedContent;
                                
                                // Auto-scroll to top during streaming (most recent at top)
                                setTimeout(() => {
                                    responseContainer.scrollTop = 0;
                                }, 50);
                            } else if (data.type === 'done') {
                                finalAudio = data.audio_base64 || null;
                            }
                        } catch (e) {}
                    }
                });
            }
            
            // Clear stored question data after streaming is complete
            currentQuestion = null;
            currentQuestionType = null;
            currentQuestionImage = null;
            
            // No audio expected since toggle OFF; keep text only
        }

        // Store current question for Q&A pairing
        let currentQuestion = null;
        let currentQuestionType = null;
        let currentQuestionImage = null;

        // Display user message (question only, no answer yet)
        function displayUserMessage(text, type, imageBase64 = null) {
            // Store the question data for when the answer comes
            currentQuestion = text;
            currentQuestionType = type;
            currentQuestionImage = imageBase64;
            
            // Don't display the question yet - it will be displayed with the answer in displayResponse
            // This prevents the duplicate question display
        }

        // Display response (answer only, will be paired with stored question)
        function displayResponse(answer, sessionInfo, language) {
            const responseContainer = document.getElementById('responseContainer');
            const responseContent = document.getElementById('responseContent');
            const responseMeta = document.getElementById('responseMeta');
            
            // Check if this is an image input that already has a Q&A pair displayed
            if (currentQuestionType === 'image') {
                // Find the first Q&A pair (most recent) and update its answer
                const firstQAPair = responseContent.querySelector('.qa-pair');
                if (firstQAPair) {
                    const answerDiv = firstQAPair.querySelector('#imageProcessingAns');
                    if (answerDiv) {
                        // Clean LaTeX and markdown for display
                        const cleanedAnswer = cleanMarkdownForDisplay(answer);
                        answerDiv.innerHTML = cleanedAnswer.replace(/\n/g, '<br>');
                    }
                }
            } else {
                // For text and voice inputs, create complete Q&A pair HTML
                let qaPairHtml = `<div class="qa-pair" style="margin-bottom: 30px; border-left: 3px solid #3b82f6; padding-left: 15px; background: #f8fafc; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">`;
                
                // Add the question part
                if (currentQuestion) {
                    qaPairHtml += `<div class="user-message" style="margin-bottom: 15px; padding: 10px; background: #e0f2fe; border-radius: 6px; border-left: 3px solid #0ea5e9;">`;
                    qaPairHtml += `<strong>You asked:</strong> ${currentQuestion}`;
                    
                    if (currentQuestionType === 'image' && currentQuestionImage) {
                        qaPairHtml += `<div class="message-image" style="margin-top: 10px;">`;
                        qaPairHtml += `<img src="data:image/jpeg;base64,${currentQuestionImage}" alt="Uploaded image" style="max-width: 200px; border-radius: 4px;">`;
                        qaPairHtml += `</div>`;
                    }
                    qaPairHtml += `</div>`;
                }
                
                // Add the answer part
                qaPairHtml += `<div class="response-content" style="padding: 10px; background: #f0fdf4; border-radius: 6px; border-left: 3px solid #22c55e;">`;
                
                // Clean LaTeX and markdown for display
                const cleanedAnswer = cleanMarkdownForDisplay(answer);
                qaPairHtml += `<strong>AI Answer:</strong><br><div style="white-space: pre-wrap; line-height: 1.6; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;">${cleanedAnswer.replace(/\n/g, '<br>')}</div>`;
                qaPairHtml += `</div>`;
                qaPairHtml += `</div>`;
                
                // Prepend complete Q&A pair to top (notebook style)
                responseContent.innerHTML = qaPairHtml + responseContent.innerHTML;
            }
            
            responseMeta.textContent = `Language: ${language || 'unknown'} | Session: ${sessionInfo?.session_id || 'N/A'}`;
            responseContainer.style.display = 'block';
            
            // Clear stored question data
            currentQuestion = null;
            currentQuestionType = null;
            currentQuestionImage = null;
            
            // Auto-scroll to top to show the most recent Q&A pair
            setTimeout(() => {
                responseContainer.scrollTop = 0;
            }, 100);
        }

        // Clean markdown and LaTeX for display (similar to backend cleaning)
        function cleanMarkdownForDisplay(text) {
            // ========================================================================
            // STEP 1: Clean LaTeX formatting (CRITICAL for display)
            // ========================================================================
            
            // Remove LaTeX display math blocks \[ ... \]
            text = text.replace(/\\\[([\s\S]*?)\\\]/g, '$1');
            
            // Remove LaTeX inline math \( ... \)
            text = text.replace(/\\\(([\s\S]*?)\\\)/g, '$1');
            
            // Clean common LaTeX commands
            text = text.replace(/\\times/g, '×');  // \times -> ×
            text = text.replace(/\\left/g, '');  // \left -> remove
            text = text.replace(/\\right/g, '');  // \right -> remove
            text = text.replace(/\\pi/g, 'π');  // \pi -> π
            text = text.replace(/\\theta/g, 'θ');  // \theta -> θ
            text = text.replace(/\\alpha/g, 'α');  // \alpha -> α
            text = text.replace(/\\beta/g, 'β');  // \beta -> β
            text = text.replace(/\\gamma/g, 'γ');  // \gamma -> γ
            text = text.replace(/\\delta/g, 'δ');  // \delta -> δ
            text = text.replace(/\\epsilon/g, 'ε');  // \epsilon -> ε
            text = text.replace(/\\lambda/g, 'λ');  // \lambda -> λ
            text = text.replace(/\\mu/g, 'μ');  // \mu -> μ
            text = text.replace(/\\sigma/g, 'σ');  // \sigma -> σ
            text = text.replace(/\\phi/g, 'φ');  // \phi -> φ
            text = text.replace(/\\omega/g, 'ω');  // \omega -> ω
            
            // Clean LaTeX fractions
            text = text.replace(/\\frac\{([^}]+)\}\{([^}]+)\}/g, '($1)/($2)');
            
            // Clean LaTeX text commands
            text = text.replace(/\\text\{([^}]+)\}/g, '$1');
            text = text.replace(/\\textbf\{([^}]+)\}/g, '$1');
            text = text.replace(/\\textit\{([^}]+)\}/g, '$1');
            
            // ========================================================================
            // STEP 2: Clean markdown formatting
            // ========================================================================
            
            // Remove bold/italic markdown but keep the content
            text = text.replace(/\*\*(.*?)\*\*/g, '$1');  // **bold** -> bold
            text = text.replace(/\*(.*?)\*/g, '$1');      // *italic* -> italic
            text = text.replace(/__(.*?)__/g, '$1');       // __bold__ -> bold
            text = text.replace(/_(.*?)_/g, '$1');         // _italic_ -> italic
            
            // Remove code formatting
            text = text.replace(/`([^`]+)`/g, '$1');       // `code` -> code
            text = text.replace(/```[\s\S]*?```/g, '');   // Remove code blocks
            
            // Remove markdown links
            text = text.replace(/\[([^\]]+)\]\([^)]+\)/g, '$1');
            
            // Clean up excessive line breaks
            text = text.replace(/\n\s*\n\s*\n/g, '\n\n');  // Multiple line breaks -> double line break
            
            return text;
        }

        // Audio output toggle
        function toggleAudioOutput() {
            audioOutputEnabled = !audioOutputEnabled;
            const audioToggle = document.getElementById('audioToggle');
            const audioToggleText = document.getElementById('audioToggleText');
            
            if (audioOutputEnabled) {
                audioToggle.classList.add('active');
                audioToggleText.textContent = '🔊 Audio Output: ON';
            } else {
                audioToggle.classList.remove('active');
                audioToggleText.textContent = '🔇 Audio Output: OFF';
                // Hide audio controls when audio output is disabled
                document.getElementById('audioControls').style.display = 'none';
            }
            
            console.log('🔊 Audio output:', audioOutputEnabled ? 'ON' : 'OFF');
        }

        // Voice recording functions (ported stable recorder with silence detection)
        let mediaRecorder; let audioChunks = []; let recordingTimeout; let silenceDetector; let audioContext; let analyser; let silenceStart; let isInitialized = false; let initializationPromise = null; const isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);

        // Pre-initialize audio context and media devices to reduce first-use latency
        async function initializeAudioSystem() {
            if (isInitialized) return Promise.resolve();
            if (initializationPromise) return initializationPromise;
            
            initializationPromise = new Promise(async (resolve, reject) => {
                try {
                    console.log('🔧 Initializing audio system...');
                    const status = document.getElementById('status');
                    status.textContent = '🔧 Initializing microphone...';
                    
                    // Request microphone permission with enhanced audio settings
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { 
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            sampleRate: 44100
                        } 
                    });
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    // Resume audio context if suspended (required for some browsers)
                    if (audioContext.state === 'suspended') {
                        await audioContext.resume();
                    }
                    
                    // Create analyser for silence detection
                    analyser = audioContext.createAnalyser();
                    analyser.smoothingTimeConstant = 0.8;
                    analyser.fftSize = 1024;
                    
                    // Stop the test stream
                    stream.getTracks().forEach(track => track.stop());
                    
                    isInitialized = true;
                    console.log('✅ Audio system initialized');
                    status.textContent = '✅ Microphone ready!';
                    
                    setTimeout(() => {
                        status.textContent = 'Ready to help! Type, speak, or upload an image';
                    }, 1000);
                    
                    resolve();
                } catch (err) {
                    console.error('❌ Audio initialization failed:', err);
                    document.getElementById('status').textContent = '❌ Microphone permission denied';
                    reject(err);
                }
            });
            
            return initializationPromise;
        }

        // Function to wait for microphone to be actually ready
        async function waitForMicrophoneReady(stream) {
            return new Promise((resolve) => {
                const status = document.getElementById('status');
                let attempts = 0;
                const maxAttempts = 50; // 5 seconds max wait
                let audioContextReady = false;
                let analyserReady = false;
                
                // Create a temporary audio context to test microphone readiness
                const tempAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                const tempAnalyser = tempAudioContext.createAnalyser();
                const microphone = tempAudioContext.createMediaStreamSource(stream);
                microphone.connect(tempAnalyser);
                
                const checkMicrophoneReady = () => {
                    attempts++;
                    
                    // Check if stream is active and has audio tracks
                    if (stream.active && stream.getAudioTracks().length > 0) {
                        const audioTrack = stream.getAudioTracks()[0];
                        
                        // Check if track is ready and not muted
                        if (audioTrack.readyState === 'live' && !audioTrack.muted) {
                            
                            // Test if audio context is working
                            if (tempAudioContext.state === 'running') {
                                audioContextReady = true;
                            }
                            
                            // Test if we can get audio data (microphone is actually working)
                            const bufferLength = tempAnalyser.frequencyBinCount;
                            const dataArray = new Uint8Array(bufferLength);
                            tempAnalyser.getByteFrequencyData(dataArray);
                            
                            // Check if we're getting any audio data (not just silence)
                            let sum = 0;
                            for (let i = 0; i < bufferLength; i++) {
                                sum += dataArray[i];
                            }
                            const average = sum / bufferLength;
                            
                            // If we have audio context running and some audio data, microphone is ready
                            if (audioContextReady && average > 0) {
                                console.log('✅ Microphone is ready! Audio level:', average);
                                status.textContent = '🎤 Microphone ready!';
                                
                                // Clean up temporary audio context
                                tempAudioContext.close();
                                resolve();
                                return;
                            }
                        }
                    }
                    
                    // If max attempts reached, proceed anyway
                    if (attempts >= maxAttempts) {
                        console.log('⚠️ Microphone readiness timeout, proceeding...');
                        status.textContent = '🎤 Starting recording...';
                        
                        // Clean up temporary audio context
                        tempAudioContext.close();
                        resolve();
                        return;
                    }
                    
                    // Check again in 100ms
                    setTimeout(checkMicrophoneReady, 100);
                };
                
                // Start checking immediately
                checkMicrophoneReady();
            });
        }

        async function startRecording() {
            try {
                // Ensure audio system is initialized first
                await initializeAudioSystem();
                
                const status = document.getElementById('status');
                status.textContent = '🎤 Initializing microphone...';
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 44100
                    } 
                });
                
                let options = {}; 
                if (!isSafari) { 
                    options = { mimeType: 'audio/webm' }; 
                }
                
                mediaRecorder = new MediaRecorder(stream, options); 
                audioChunks = []; 
                
                const voiceBtn = document.getElementById('voiceBtn');
                voiceBtn.classList.add('active'); 
                status.textContent = '🎤 Waiting for microphone...';
                
                // Wait for microphone to be actually ready (not hard-coded delay)
                await waitForMicrophoneReady(stream);
                
                // Now start recording
                isRecording = true;
                status.textContent = '🎤 Recording... Speak your question!';
                
                mediaRecorder.ondataavailable = (e) => { 
                    audioChunks.push(e.data); 
                };
                
                mediaRecorder.onstop = async () => { 
                    const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/wav' }); 
                    await sendAudioToAPINormal(audioBlob); 
                };
                
                // Start recording with a small delay to ensure everything is ready
                setTimeout(() => {
                    if (isRecording) {
                        mediaRecorder.start();
                        setupSilenceDetection(stream);
                        recordingTimeout = setTimeout(() => { 
                            if (isRecording) stopRecording(); 
                        }, 20000);
                    }
                }, 200);
                
            } catch (err) { 
                console.error('Mic error:', err); 
                document.getElementById('status').textContent = '❌ Microphone permission denied'; 
            }
        }

        function setupSilenceDetection(stream) {
            // Create a fresh analyser for this recording session
            const recordingAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            const recordingAnalyser = recordingAudioContext.createAnalyser();
            recordingAnalyser.smoothingTimeConstant = 0.8;
            recordingAnalyser.fftSize = 1024;
            
            const microphone = recordingAudioContext.createMediaStreamSource(stream);
            microphone.connect(recordingAnalyser);
            silenceStart = null;
            
            silenceDetector = setInterval(() => {
                if (!isRecording) { 
                    clearInterval(silenceDetector); 
                    return; 
                } 
                
                const bufferLength = recordingAnalyser.frequencyBinCount; 
                const dataArray = new Uint8Array(bufferLength); 
                recordingAnalyser.getByteFrequencyData(dataArray); 
                
                let sum = 0; 
                for (let i = 0; i < bufferLength; i++) { 
                    sum += dataArray[i]; 
                } 
                
                const average = sum / bufferLength; 
                const SILENCE_THRESHOLD = 10; 
                const SILENCE_DURATION = 2000; 
                
                if (average < SILENCE_THRESHOLD) { 
                    if (!silenceStart) {
                        silenceStart = Date.now(); 
                    } else if (Date.now() - silenceStart > SILENCE_DURATION) { 
                        stopRecording(); 
                    } 
                } else { 
                    silenceStart = null; 
                } 
            }, 100);
        }

        function stopRecording() {
            if (!mediaRecorder || !isRecording) return; 
            clearTimeout(recordingTimeout); 
            clearInterval(silenceDetector); 
            isRecording = false; 
            document.getElementById('voiceBtn').classList.remove('active'); 
            const status = document.getElementById('status'); 
            status.textContent = '⏳ Processing...'; 
            mediaRecorder.stop(); 
            mediaRecorder.stream.getTracks().forEach(t => t.stop()); 
            // Note: We don't close the pre-initialized audioContext here
            // as it's used for pre-initialization, not recording
        }

        async function sendAudioToAPINormal(audioBlob) {
            const userId = document.getElementById('userId').value || 'user123'; 
            const videoId = document.getElementById('videoId').value || 'Area_Circle'; 
            const language = document.getElementById('languageSelect').value || ''; 
            const status = document.getElementById('status');
            
            try { 
                const base64Audio = await blobToBase64(audioBlob); 
                const body = { user_id: userId, video_id: videoId, audio_file_base64: base64Audio }; 
                if (language) body.language = language; 
                
                const resp = await fetch('http://localhost:5001/api/ask_tutor', { 
                    method: 'POST', 
                    headers: { 'Content-Type': 'application/json' }, 
                    body: JSON.stringify(body) 
                }); 
                
                const data = await resp.json(); 
                
                if (data.success) { 
                    // Store user message data
                    if (data.question) {
                        displayUserMessage(data.question, 'voice');
                    }
                    
                    // Display the user's question immediately for voice input (similar to image input)
                    const responseContainer = document.getElementById('responseContainer');
                    const responseContent = document.getElementById('responseContent');
                    responseContainer.style.display = 'block';
                    
                    let messageHtml = `<div class="qa-pair" style="margin-bottom: 30px; border-left: 3px solid #3b82f6; padding-left: 15px; background: #f8fafc; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">`;
                    messageHtml += `<div class="user-message" style="margin-bottom: 15px; padding: 10px; background: #e0f2fe; border-radius: 6px; border-left: 3px solid #0ea5e9;">`;
                    messageHtml += `<strong>You asked:</strong> ${data.question}`;
                    messageHtml += `<div style="font-size: 0.9em; color: #666; margin-top: 5px;">🎤 Voice Input</div>`;
                    messageHtml += `</div>`;
                    messageHtml += `<div class="response-content" style="padding: 10px; background: #f0fdf4; border-radius: 6px; border-left: 3px solid #22c55e;">`;
                    messageHtml += `<strong>AI Answer:</strong><br><div style="white-space: pre-wrap; line-height: 1.6; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;">${data.answer}</div></div></div>`;
                    
                    responseContent.insertAdjacentHTML('afterbegin', messageHtml);
                    responseContainer.scrollIntoView({ behavior: 'smooth' });
                    
                    if (data.audio_base64 && audioOutputEnabled) playAudio(data.audio_base64); 
                    status.textContent = '✅ Response received!'; 
                } else { 
                    displayError('Failed to get response', data.error || ''); 
                    status.textContent = '❌ Error occurred'; 
                } 
            } catch (e) { 
                console.error(e); 
                displayError('Failed to connect to server', 'Check Flask on 5001'); 
                status.textContent = '❌ Connection error'; 
            } finally { 
                setTimeout(() => { 
                    status.textContent = 'Ready to help! Type, speak, or upload an image'; 
                }, 2000); 
            }
        }

        function blobToBase64(blob){ return new Promise((resolve,reject)=>{ const reader=new FileReader(); reader.onloadend=()=>resolve(reader.result.split(',')[1]); reader.onerror=reject; reader.readAsDataURL(blob); }); }

        // Audio playback functions
        function playAudio(audioBase64) {
            try {
                const audioBlob = new Blob([Uint8Array.from(atob(audioBase64), c => c.charCodeAt(0))], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                
                currentAudio = new Audio(audioUrl);
                currentAudio.play();
                
                // Show audio controls only if audio output is enabled
                if (audioOutputEnabled) {
                    document.getElementById('audioControls').style.display = 'flex';
                    document.getElementById('playBtn').disabled = true;
                    document.getElementById('playBtn').textContent = '⏸️';
                    document.getElementById('stopBtn').disabled = false;
                }
                
                currentAudio.onended = function() {
                    if (audioOutputEnabled) {
                        document.getElementById('playBtn').disabled = false;
                        document.getElementById('playBtn').textContent = '▶️';
                        document.getElementById('stopBtn').disabled = true;
                    }
                };
                
            } catch (error) {
                console.error('❌ Audio playback error:', error);
            }
        }

        function playCurrentAudio() {
            if (currentAudio) {
                if (currentAudio.paused) {
                    currentAudio.play();
                    document.getElementById('playBtn').textContent = '⏸️';
                } else {
                    currentAudio.pause();
                    document.getElementById('playBtn').textContent = '▶️';
                }
            }
        }

        function stopCurrentAudio() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                document.getElementById('playBtn').textContent = '▶️';
            }
        }

        // Utility functions
        function fileToBase64(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result.split(',')[1]);
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
        }

        function displayError(title, message) {
            console.error(`❌ ${title}: ${message}`);
            document.getElementById('status').textContent = `❌ ${title}: ${message}`;
        }

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', function() {
            initializeMultimodalChatbar();
            // Ensure toggle UI reflects default OFF
            const toggle = document.getElementById('audioToggle');
            if (!audioOutputEnabled) toggle.classList.remove('active');
            console.log('🎓 AI Math Tutor - Enhanced Multimodal Chat Interface Ready!');
            
            // Pre-initialize audio system after a short delay to avoid blocking page load
            setTimeout(() => {
                console.log('🔧 Pre-initializing audio system...');
                initializeAudioSystem().catch(err => {
                    console.log('⚠️ Audio pre-initialization failed (will initialize on first use):', err.message);
                });
            }, 2000);
            
            // Also initialize on first user interaction (required by some browsers)
            let hasInitializedOnInteraction = false;
            const initializeOnInteraction = () => {
                if (!hasInitializedOnInteraction && !isInitialized) {
                    hasInitializedOnInteraction = true;
                    console.log('🔧 Initializing audio system on user interaction...');
                    initializeAudioSystem().catch(err => {
                        console.log('⚠️ Audio initialization on interaction failed:', err.message);
                    });
                }
            };
            
            // Listen for any user interaction
            document.addEventListener('click', initializeOnInteraction, { once: true });
            document.addEventListener('keydown', initializeOnInteraction, { once: true });
            document.addEventListener('touchstart', initializeOnInteraction, { once: true });
        });
    </script>
</body>
</html>
